---
version: "2.0"

services:
  llama-3-70b:
    image: vllm/vllm-openai:latest
    expose:
      - port: 8001
        as: 80
        to:
          - global: true
    env:
      - MODEL=meta-llama/Meta-Llama-3.1-70B-Instruct
      - TENSOR_PARALLEL_SIZE=2
      - MAX_MODEL_LEN=4096
      - GPU_MEMORY_UTILIZATION=0.9
    command:
      - "--model"
      - "meta-llama/Meta-Llama-3.1-70B-Instruct"
      - "--tensor-parallel-size"
      - "2"
      - "--max-model-len"
      - "4096"
      - "--gpu-memory-utilization"
      - "0.9"

profiles:
  compute:
    llama-3-70b:
      resources:
        cpu:
          units: 8
        memory:
          size: 32Gi
        gpu:
          units: 2
          attributes:
            vendor:
              nvidia:
                - model: a100
                - model: a6000
        storage:
          - size: 300Gi
          - mount: /root/.cache
            size: 150Gi

  placement:
    dcloud:
      pricing:
        llama-3-70b:
          denom: uakt
          amount: 5000  # ~$50-75/month for 2x A100

deployment:
  llama-3-70b:
    dcloud:
      profile: llama-3-70b
      count: 1
